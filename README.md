
# Machine Learning Projects ğŸ§ ğŸ“Š

Welcome to my **Machine Learning** repository! This repo contains hands-on implementations of various ML models and core concepts that I built while learning data science and machine learning. Each model is built from scratch or with the help of libraries like `scikit-learn`, `Pandas`, `NumPy`, and is documented using **Jupyter Notebooks** for easy understanding and reproducibility.

---

## ğŸ” Repository Structure

All files are organized under the `src/` directory:

```
src/
â”œâ”€â”€ regression/
â”‚   â”œâ”€â”€ linear_regression.ipynb
â”‚   â”œâ”€â”€ logistic_regression.ipynb
â”‚   â””â”€â”€ ...
â”œâ”€â”€ classification/
â”‚   â”œâ”€â”€ knn.ipynb
â”‚   â”œâ”€â”€ decision_tree.ipynb
â”‚   â””â”€â”€ ...
â”œâ”€â”€ unsupervised/
â”‚   â”œâ”€â”€ kmeans.ipynb
â”‚   â”œâ”€â”€ pca.ipynb
â”‚   â””â”€â”€ ...
â””â”€â”€ model_evaluation/
    â”œâ”€â”€ kfold_cross_validation.ipynb
    â”œâ”€â”€ bagging.ipynb
    â””â”€â”€ ...
```

---

## âœ… Topics Covered

- Supervised Learning
  - Linear Regression
  - Logistic Regression
  - K-Nearest Neighbors (KNN)
  - Decision Trees
  - Support Vector Machines (SVM)
  - Naive Bayes

- Unsupervised Learning
  - K-Means Clustering
  - Principal Component Analysis (PCA)

- Model Evaluation
  - K-Fold Cross Validation
  - Confusion Matrix
  - Hyperparameter Tuning (GridSearchCV)

- Training Techniques / Optimization
  - Gradient Descent 
  - Regularization (L1 & L2) 

- Feature Engineering & Preprocessing
  - Outlier Removal
  - Normalization/Scaling
  - One-Hot Encoding

---

## ğŸ›  Technologies Used

- Python
- Jupyter Notebooks
- scikit-learn
- Pandas
- NumPy
- Matplotlib & Seaborn

---

## ğŸ“ How to Use

1. Clone the repository:
```bash
git clone https://github.com/sharaf-ahmd/Machine_Learning.git
```

2. Navigate to the `src/` folder and open the notebooks using **Jupyter Notebook** or **VS Code** with Jupyter support.

3. Run the cells to explore models and visualizations.

---



## â­ï¸ Star this Repo

If you found this helpful, give it a â­ï¸! It helps others discover it too.
